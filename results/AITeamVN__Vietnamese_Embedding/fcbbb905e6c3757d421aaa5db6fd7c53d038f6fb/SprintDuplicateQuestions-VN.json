{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 26.87,
                "hf_subset": "default",
                "dot_accuracy": 0.9978849165971166,
                "dot_ap": 0.9527886463031536,
                "dot_f1": 0.8914956011730205,
                "dot_accuracy_threshold": 0.6570978760719299,
                "dot_f1_threshold": 0.6570978760719299,
                "dot_precision": 0.926829268292683,
                "dot_recall": 0.8587570621468926,
                "euclidean_accuracy": 0.9978849165971166,
                "euclidean_ap": 0.9527886463031539,
                "euclidean_f1": 0.8914956011730205,
                "euclidean_accuracy_threshold": 0.8281329870223999,
                "euclidean_f1_threshold": 0.8281329870223999,
                "euclidean_precision": 0.926829268292683,
                "euclidean_recall": 0.8587570621468926,
                "manhattan_accuracy": 0.9978734837138578,
                "manhattan_ap": 0.9522891166162963,
                "manhattan_f1": 0.890716803760282,
                "manhattan_accuracy_threshold": 20.952655792236328,
                "manhattan_f1_threshold": 20.9853458404541,
                "manhattan_precision": 0.9277845777233782,
                "manhattan_recall": 0.8564971751412429,
                "max_accuracy": 0.9978849165971166,
                "max_ap": 0.9527886463031539,
                "max_f1": 0.8914956011730205,
                "main_score": 0.9527886463031539,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 27.51,
                "hf_subset": "default",
                "dot_accuracy": 0.9979955406409765,
                "dot_ap": 0.960750038550674,
                "dot_f1": 0.8995535714285715,
                "dot_accuracy_threshold": 0.6289548873901367,
                "dot_f1_threshold": 0.6200573444366455,
                "dot_precision": 0.8955555555555555,
                "dot_recall": 0.9035874439461884,
                "euclidean_accuracy": 0.9979955406409765,
                "euclidean_ap": 0.9607500385506741,
                "euclidean_f1": 0.8995535714285715,
                "euclidean_accuracy_threshold": 0.8614464998245239,
                "euclidean_f1_threshold": 0.8717139959335327,
                "euclidean_precision": 0.8955555555555555,
                "euclidean_recall": 0.9035874439461884,
                "manhattan_accuracy": 0.9979955406409765,
                "manhattan_ap": 0.9606603525425462,
                "manhattan_f1": 0.8994946659180235,
                "manhattan_accuracy_threshold": 21.57628631591797,
                "manhattan_f1_threshold": 21.976707458496094,
                "manhattan_precision": 0.9010123734533183,
                "manhattan_recall": 0.897982062780269,
                "max_accuracy": 0.9979955406409765,
                "max_ap": 0.9607500385506741,
                "max_f1": 0.8995535714285715,
                "main_score": 0.9607500385506741,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}