{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 11.63,
                "hf_subset": "default",
                "dot_accuracy": 0.9983765305772463,
                "dot_ap": 0.9653743906706943,
                "dot_f1": 0.917633410672854,
                "dot_accuracy_threshold": 0.7544083595275879,
                "dot_f1_threshold": 0.7544083595275879,
                "dot_precision": 0.9427890345649583,
                "dot_recall": 0.8937853107344633,
                "euclidean_accuracy": 0.9983765305772463,
                "euclidean_ap": 0.9653743906706943,
                "euclidean_f1": 0.917633410672854,
                "euclidean_accuracy_threshold": 0.7008446455001831,
                "euclidean_f1_threshold": 0.7008446455001831,
                "euclidean_precision": 0.9427890345649583,
                "euclidean_recall": 0.8937853107344633,
                "manhattan_accuracy": 0.9983193661609522,
                "manhattan_ap": 0.9648259897037258,
                "manhattan_f1": 0.9149797570850202,
                "manhattan_accuracy_threshold": 17.621498107910156,
                "manhattan_f1_threshold": 17.823684692382812,
                "manhattan_precision": 0.9372037914691943,
                "manhattan_recall": 0.8937853107344633,
                "max_accuracy": 0.9983765305772463,
                "max_ap": 0.9653744158712719,
                "max_f1": 0.917633410672854,
                "main_score": 0.9653744158712719,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 13.82,
                "hf_subset": "default",
                "dot_accuracy": 0.998445980946375,
                "dot_ap": 0.9723735116937526,
                "dot_f1": 0.9231619679380874,
                "dot_accuracy_threshold": 0.7365323901176453,
                "dot_f1_threshold": 0.7238262891769409,
                "dot_precision": 0.910577971646674,
                "dot_recall": 0.9360986547085202,
                "euclidean_accuracy": 0.998445980946375,
                "euclidean_ap": 0.9723735116937526,
                "euclidean_f1": 0.9231619679380874,
                "euclidean_accuracy_threshold": 0.7259029746055603,
                "euclidean_f1_threshold": 0.7432008385658264,
                "euclidean_precision": 0.910577971646674,
                "euclidean_recall": 0.9360986547085202,
                "manhattan_accuracy": 0.998445980946375,
                "manhattan_ap": 0.9718986885849112,
                "manhattan_f1": 0.9221218961625283,
                "manhattan_accuracy_threshold": 18.215648651123047,
                "manhattan_f1_threshold": 18.4332275390625,
                "manhattan_precision": 0.928409090909091,
                "manhattan_recall": 0.9159192825112108,
                "max_accuracy": 0.998445980946375,
                "max_ap": 0.9723735116937526,
                "max_f1": 0.9231619679380874,
                "main_score": 0.9723735116937526,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}