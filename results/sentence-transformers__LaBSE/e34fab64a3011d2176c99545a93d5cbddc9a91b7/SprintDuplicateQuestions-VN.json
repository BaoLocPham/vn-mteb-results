{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 5.52,
                "hf_subset": "default",
                "dot_accuracy": 0.9957584003109744,
                "dot_ap": 0.825543435803705,
                "dot_f1": 0.7761194029850746,
                "dot_accuracy_threshold": 0.730046808719635,
                "dot_f1_threshold": 0.7238767743110657,
                "dot_precision": 0.8227848101265823,
                "dot_recall": 0.7344632768361582,
                "euclidean_accuracy": 0.9957584003109744,
                "euclidean_ap": 0.825543257636429,
                "euclidean_f1": 0.7761194029850746,
                "euclidean_accuracy_threshold": 0.7347832918167114,
                "euclidean_f1_threshold": 0.7431328296661377,
                "euclidean_precision": 0.8227848101265823,
                "euclidean_recall": 0.7344632768361582,
                "manhattan_accuracy": 0.9952896520973624,
                "manhattan_ap": 0.8008673804204032,
                "manhattan_f1": 0.7501512401693889,
                "manhattan_accuracy_threshold": 15.605018615722656,
                "manhattan_f1_threshold": 15.819501876831055,
                "manhattan_precision": 0.8072916666666666,
                "manhattan_recall": 0.7005649717514124,
                "max_accuracy": 0.9957584003109744,
                "max_ap": 0.825543435803705,
                "max_f1": 0.7761194029850746,
                "main_score": 0.825543435803705,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 6.09,
                "hf_subset": "default",
                "dot_accuracy": 0.9947636314497421,
                "dot_ap": 0.7820684091564617,
                "dot_f1": 0.7308970099667775,
                "dot_accuracy_threshold": 0.7292945981025696,
                "dot_f1_threshold": 0.7095476388931274,
                "dot_precision": 0.7221006564551422,
                "dot_recall": 0.7399103139013453,
                "euclidean_accuracy": 0.9947636314497421,
                "euclidean_ap": 0.7820684091564616,
                "euclidean_f1": 0.7308970099667775,
                "euclidean_accuracy_threshold": 0.7358062267303467,
                "euclidean_f1_threshold": 0.7621709108352661,
                "euclidean_precision": 0.7221006564551422,
                "euclidean_recall": 0.7399103139013453,
                "manhattan_accuracy": 0.9941555370374541,
                "manhattan_ap": 0.7366800033685228,
                "manhattan_f1": 0.6937187326292386,
                "manhattan_accuracy_threshold": 15.882421493530273,
                "manhattan_f1_threshold": 16.279815673828125,
                "manhattan_precision": 0.6879823594266814,
                "manhattan_recall": 0.6995515695067265,
                "max_accuracy": 0.9947636314497421,
                "max_ap": 0.7820684091564618,
                "max_f1": 0.7308970099667775,
                "main_score": 0.7820684091564618,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}