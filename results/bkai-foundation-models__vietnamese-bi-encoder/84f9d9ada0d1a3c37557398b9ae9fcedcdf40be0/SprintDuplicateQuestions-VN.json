{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 4.26,
                "hf_subset": "default",
                "dot_accuracy": 0.9963757760069512,
                "dot_ap": 0.8913844725462123,
                "dot_f1": 0.8137629710540689,
                "dot_accuracy_threshold": 22.193546295166016,
                "dot_f1_threshold": 21.072265625,
                "dot_precision": 0.7875264270613108,
                "dot_recall": 0.8418079096045198,
                "euclidean_accuracy": 0.996924554403375,
                "euclidean_ap": 0.9130703548071459,
                "euclidean_f1": 0.8434430964760254,
                "euclidean_accuracy_threshold": 4.74558162689209,
                "euclidean_f1_threshold": 5.027246475219727,
                "euclidean_precision": 0.8628841607565012,
                "euclidean_recall": 0.8248587570621468,
                "manhattan_accuracy": 0.9969016886368574,
                "manhattan_ap": 0.9098409631201533,
                "manhattan_f1": 0.8414985590778099,
                "manhattan_accuracy_threshold": 103.46778869628906,
                "manhattan_f1_threshold": 109.52671813964844,
                "manhattan_precision": 0.8588235294117647,
                "manhattan_recall": 0.8248587570621468,
                "max_accuracy": 0.9969359872866338,
                "max_ap": 0.9130939584998351,
                "max_f1": 0.8434430964760254,
                "main_score": 0.9130939584998351,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 6.3,
                "hf_subset": "default",
                "dot_accuracy": 0.9965203486407964,
                "dot_ap": 0.8960956444885725,
                "dot_f1": 0.8311546840958605,
                "dot_accuracy_threshold": 21.0753173828125,
                "dot_f1_threshold": 20.588298797607422,
                "dot_precision": 0.8082627118644068,
                "dot_recall": 0.8553811659192825,
                "euclidean_accuracy": 0.9971284430530843,
                "euclidean_ap": 0.9223166693641116,
                "euclidean_f1": 0.858254585881045,
                "euclidean_accuracy_threshold": 5.21061897277832,
                "euclidean_f1_threshold": 5.21061897277832,
                "euclidean_precision": 0.8511576626240352,
                "euclidean_recall": 0.8654708520179372,
                "manhattan_accuracy": 0.9971059210378145,
                "manhattan_ap": 0.9199191065621617,
                "manhattan_f1": 0.8560354374307863,
                "manhattan_accuracy_threshold": 113.07011413574219,
                "manhattan_f1_threshold": 113.96591186523438,
                "manhattan_precision": 0.8457330415754923,
                "manhattan_recall": 0.8665919282511211,
                "max_accuracy": 0.9971284430530843,
                "max_ap": 0.9223166693641116,
                "max_f1": 0.858254585881045,
                "main_score": 0.9223166693641116,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}