{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 5.61,
                "hf_subset": "default",
                "dot_accuracy": 0.9954154138132095,
                "dot_ap": 0.8073774650701571,
                "dot_f1": 0.7531083481349911,
                "dot_accuracy_threshold": 0.8189781308174133,
                "dot_f1_threshold": 0.7928808927536011,
                "dot_precision": 0.7910447761194029,
                "dot_recall": 0.7186440677966102,
                "euclidean_accuracy": 0.9954154138132095,
                "euclidean_ap": 0.8073772780650268,
                "euclidean_f1": 0.7531083481349911,
                "euclidean_accuracy_threshold": 0.6017006635665894,
                "euclidean_f1_threshold": 0.643613338470459,
                "euclidean_precision": 0.7910447761194029,
                "euclidean_recall": 0.7186440677966102,
                "manhattan_accuracy": 0.9954497124629861,
                "manhattan_ap": 0.8060844519170168,
                "manhattan_f1": 0.7531992687385741,
                "manhattan_accuracy_threshold": 9.520490646362305,
                "manhattan_f1_threshold": 9.8807373046875,
                "manhattan_precision": 0.8174603174603174,
                "manhattan_recall": 0.6983050847457627,
                "max_accuracy": 0.9954497124629861,
                "max_ap": 0.8073774650701571,
                "max_f1": 0.7531992687385741,
                "main_score": 0.8073774650701571,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 6.37,
                "hf_subset": "default",
                "dot_accuracy": 0.9943807571901534,
                "dot_ap": 0.7517234228552099,
                "dot_f1": 0.6939010356731875,
                "dot_accuracy_threshold": 0.8129597902297974,
                "dot_f1_threshold": 0.7815587520599365,
                "dot_precision": 0.7127659574468085,
                "dot_recall": 0.6760089686098655,
                "euclidean_accuracy": 0.9943807571901534,
                "euclidean_ap": 0.7517234204501606,
                "euclidean_f1": 0.6939010356731875,
                "euclidean_accuracy_threshold": 0.611621081829071,
                "euclidean_f1_threshold": 0.66097092628479,
                "euclidean_precision": 0.7127659574468085,
                "euclidean_recall": 0.6760089686098655,
                "manhattan_accuracy": 0.9944145402130583,
                "manhattan_ap": 0.7500802467923353,
                "manhattan_f1": 0.6922209695603158,
                "manhattan_accuracy_threshold": 9.434799194335938,
                "manhattan_f1_threshold": 10.389960289001465,
                "manhattan_precision": 0.6961451247165533,
                "manhattan_recall": 0.6883408071748879,
                "max_accuracy": 0.9944145402130583,
                "max_ap": 0.7517234228552099,
                "max_f1": 0.6939010356731875,
                "main_score": 0.7517234228552099,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}