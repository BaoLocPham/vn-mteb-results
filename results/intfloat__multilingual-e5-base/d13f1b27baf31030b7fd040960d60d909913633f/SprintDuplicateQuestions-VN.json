{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 4.75,
                "hf_subset": "default",
                "dot_accuracy": 0.9975190643328341,
                "dot_ap": 0.9316213168686591,
                "dot_f1": 0.8768197088465846,
                "dot_accuracy_threshold": 0.915529727935791,
                "dot_f1_threshold": 0.9129436016082764,
                "dot_precision": 0.8690344062153164,
                "dot_recall": 0.8847457627118644,
                "euclidean_accuracy": 0.9975190643328341,
                "euclidean_ap": 0.931621316868659,
                "euclidean_f1": 0.8768197088465846,
                "euclidean_accuracy_threshold": 0.4110235869884491,
                "euclidean_f1_threshold": 0.4172680974006653,
                "euclidean_precision": 0.8690344062153164,
                "euclidean_recall": 0.8847457627118644,
                "manhattan_accuracy": 0.9973361382006928,
                "manhattan_ap": 0.9277610864154364,
                "manhattan_f1": 0.8707709373266779,
                "manhattan_accuracy_threshold": 9.14516830444336,
                "manhattan_f1_threshold": 9.226604461669922,
                "manhattan_precision": 0.855119825708061,
                "manhattan_recall": 0.8870056497175142,
                "max_accuracy": 0.9975190643328341,
                "max_ap": 0.9316213937654559,
                "max_f1": 0.8768197088465846,
                "main_score": 0.9316213937654559,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 7.04,
                "hf_subset": "default",
                "dot_accuracy": 0.9977027544424675,
                "dot_ap": 0.9498290267219398,
                "dot_f1": 0.8843537414965986,
                "dot_accuracy_threshold": 0.9108918309211731,
                "dot_f1_threshold": 0.9101986885070801,
                "dot_precision": 0.8944954128440367,
                "dot_recall": 0.874439461883408,
                "euclidean_accuracy": 0.9977027544424675,
                "euclidean_ap": 0.9498280053980283,
                "euclidean_f1": 0.8843537414965986,
                "euclidean_accuracy_threshold": 0.42215681076049805,
                "euclidean_f1_threshold": 0.42379528284072876,
                "euclidean_precision": 0.8944954128440367,
                "euclidean_recall": 0.874439461883408,
                "manhattan_accuracy": 0.9976464494042927,
                "manhattan_ap": 0.9469688258308959,
                "manhattan_f1": 0.8800917957544464,
                "manhattan_accuracy_threshold": 9.140239715576172,
                "manhattan_f1_threshold": 9.221003532409668,
                "manhattan_precision": 0.9012925969447708,
                "manhattan_recall": 0.8598654708520179,
                "max_accuracy": 0.9977027544424675,
                "max_ap": 0.9498290267219398,
                "max_f1": 0.8843537414965986,
                "main_score": 0.9498290267219398,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}