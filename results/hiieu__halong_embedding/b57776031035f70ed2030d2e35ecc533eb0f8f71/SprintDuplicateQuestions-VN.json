{
  "dataset_revision": null,
  "mteb_dataset_name": "SprintDuplicateQuestions-VN",
  "mteb_version": "1.7.52",
  "test": {
    "cos_sim": {
      "accuracy": 0.9978391850640813,
      "accuracy_threshold": 0.701164960861206,
      "ap": 0.9522973446056062,
      "f1": 0.8908045977011494,
      "f1_threshold": 0.6895322799682617,
      "precision": 0.9064327485380117,
      "recall": 0.8757062146892656
    },
    "dot": {
      "accuracy": 0.9978391850640813,
      "accuracy_threshold": 0.7011648416519165,
      "ap": 0.9522973446056062,
      "f1": 0.8908045977011494,
      "f1_threshold": 0.6895322799682617,
      "precision": 0.9064327485380117,
      "recall": 0.8757062146892656
    },
    "euclidean": {
      "accuracy": 0.9978391850640813,
      "accuracy_threshold": 0.7730908393859863,
      "ap": 0.952297344605606,
      "f1": 0.8908045977011494,
      "f1_threshold": 0.7879946231842041,
      "precision": 0.9064327485380117,
      "recall": 0.8757062146892656
    },
    "evaluation_time": 4.56,
    "manhattan": {
      "accuracy": 0.9978163192975636,
      "accuracy_threshold": 17.176424026489258,
      "ap": 0.9504187610412475,
      "f1": 0.8904188181296614,
      "f1_threshold": 17.316734313964844,
      "precision": 0.9044289044289044,
      "recall": 0.8768361581920904
    },
    "max": {
      "accuracy": 0.9978391850640813,
      "ap": 0.9522973446056062,
      "f1": 0.8908045977011494
    }
  },
  "validation": {
    "cos_sim": {
      "accuracy": 0.9979279745951668,
      "accuracy_threshold": 0.6831448078155518,
      "ap": 0.9631327083596963,
      "f1": 0.8934065934065935,
      "f1_threshold": 0.6484550833702087,
      "precision": 0.8760775862068966,
      "recall": 0.9114349775784754
    },
    "dot": {
      "accuracy": 0.9979279745951668,
      "accuracy_threshold": 0.6831449270248413,
      "ap": 0.9631327083596963,
      "f1": 0.8934065934065935,
      "f1_threshold": 0.6484550833702087,
      "precision": 0.8760775862068966,
      "recall": 0.9114349775784754
    },
    "euclidean": {
      "accuracy": 0.9979279745951668,
      "accuracy_threshold": 0.796059250831604,
      "ap": 0.9631327083596966,
      "f1": 0.8934065934065935,
      "f1_threshold": 0.8385045528411865,
      "precision": 0.8760775862068966,
      "recall": 0.9114349775784754
    },
    "evaluation_time": 6.8,
    "manhattan": {
      "accuracy": 0.9978378865340871,
      "accuracy_threshold": 17.433528900146484,
      "ap": 0.961973500588178,
      "f1": 0.8924972004479282,
      "f1_threshold": 18.13722038269043,
      "precision": 0.8914988814317674,
      "recall": 0.8934977578475336
    },
    "max": {
      "accuracy": 0.9979279745951668,
      "ap": 0.9631327083596966,
      "f1": 0.8934065934065935
    }
  }
}