{
    "dataset_revision": "2552beae0e4fe7fe05d088814f78a4c309ad2219",
    "mteb_dataset_name": "SprintDuplicateQuestions-VN",
    "mteb_version": null,
    "task_name": "SprintDuplicateQuestions-VN",
    "scores": {
        "test": [
            {
                "evaluation_time": 9.85,
                "hf_subset": "default",
                "dot_accuracy": 0.9970503161192221,
                "dot_ap": 0.9141628316833574,
                "dot_f1": 0.8487690504103165,
                "dot_accuracy_threshold": 0.9258898496627808,
                "dot_f1_threshold": 0.9246476888656616,
                "dot_precision": 0.881851400730816,
                "dot_recall": 0.8180790960451978,
                "euclidean_accuracy": 0.9970503161192221,
                "euclidean_ap": 0.9141634044383192,
                "euclidean_f1": 0.8487690504103165,
                "euclidean_accuracy_threshold": 0.3849940299987793,
                "euclidean_f1_threshold": 0.38820695877075195,
                "euclidean_precision": 0.881851400730816,
                "euclidean_recall": 0.8180790960451978,
                "manhattan_accuracy": 0.9970160174694456,
                "manhattan_ap": 0.9167060008161036,
                "manhattan_f1": 0.8483439860546194,
                "manhattan_accuracy_threshold": 6.06013298034668,
                "manhattan_f1_threshold": 6.0675554275512695,
                "manhattan_precision": 0.8732057416267942,
                "manhattan_recall": 0.8248587570621468,
                "max_accuracy": 0.9970503161192221,
                "max_ap": 0.9167060008161036,
                "max_f1": 0.8487690504103165,
                "main_score": 0.9167060008161036,
                "languages": [
                    "vie-Latn"
                ]
            }
        ],
        "validation": [
            {
                "evaluation_time": 10.34,
                "hf_subset": "default",
                "dot_accuracy": 0.9973761852210535,
                "dot_ap": 0.9366680003600464,
                "dot_f1": 0.8706896551724138,
                "dot_accuracy_threshold": 0.9209418892860413,
                "dot_f1_threshold": 0.9149036407470703,
                "dot_precision": 0.8381742738589212,
                "dot_recall": 0.905829596412556,
                "euclidean_accuracy": 0.9973761852210535,
                "euclidean_ap": 0.9366680003600463,
                "euclidean_f1": 0.8706896551724138,
                "euclidean_accuracy_threshold": 0.397638201713562,
                "euclidean_f1_threshold": 0.41254425048828125,
                "euclidean_precision": 0.8381742738589212,
                "euclidean_recall": 0.905829596412556,
                "manhattan_accuracy": 0.9974662732821333,
                "manhattan_ap": 0.9393193910874201,
                "manhattan_f1": 0.8720864127345083,
                "manhattan_accuracy_threshold": 6.224420070648193,
                "manhattan_f1_threshold": 6.226656436920166,
                "manhattan_precision": 0.8846597462514417,
                "manhattan_recall": 0.8598654708520179,
                "max_accuracy": 0.9974662732821333,
                "max_ap": 0.9393193910874201,
                "max_f1": 0.8720864127345083,
                "main_score": 0.9393193910874201,
                "languages": [
                    "vie-Latn"
                ]
            }
        ]
    },
    "evaluation_time": null
}